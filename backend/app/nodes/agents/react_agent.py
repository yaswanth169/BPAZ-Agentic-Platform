"""
BPAZ-Agentic-Platform ReactAgent Node - Advanced AI Agent Orchestration
==========================================================

This module implements a sophisticated ReactAgent node that serves as the orchestration
brain of the BPAZ-Agentic-Platform platform. Built on LangChain's proven ReAct (Reasoning + Acting)
framework, it provides enterprise-grade agent capabilities with advanced tool integration,
memory management, and multilingual support.

ARCHITECTURAL OVERVIEW:
======================

The ReactAgent operates on the ReAct paradigm:
1. **Reason**: Analyze the problem and plan actions
2. **Act**: Execute tools to gather information or perform actions  
3. **Observe**: Process tool results and update understanding
4. **Repeat**: Continue until the goal is achieved

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ReactAgent Architecture                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  User Input  â†’  [Reasoning Engine]  â†’  [Tool Selection]     â”‚
â”‚      â†“               â†‘                       â†“              â”‚
â”‚  [Memory]  â†  [Result Processing]  â†  [Tool Execution]      â”‚
â”‚      â†“               â†‘                       â†“              â”‚
â”‚  [Context]  â†’  [Response Generation]  â†  [Observations]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KEY INNOVATIONS:
===============

1. **Multilingual Intelligence**: Native English support with cultural context and optional language adapters
2. **Efficiency Optimization**: Smart tool usage to minimize unnecessary calls
3. **Memory Integration**: Sophisticated conversation history management
4. **Retriever Tool Support**: Seamless RAG integration with document search
5. **Error Resilience**: Robust error handling with graceful degradation
6. **Performance Monitoring**: Built-in execution tracking and optimization

TOOL ECOSYSTEM:
==============

The agent supports multiple tool types:
- **Search Tools**: Web search, document retrieval, knowledge base queries
- **API Tools**: External service integration, data fetching
- **Processing Tools**: Text analysis, data transformation
- **Memory Tools**: Conversation history, context management
- **Custom Tools**: User-defined business logic tools

MEMORY ARCHITECTURE:
===================

Advanced memory management with multiple layers:
- **Short-term Memory**: Current conversation context
- **Long-term Memory**: Persistent user preferences and history  
- **Working Memory**: Intermediate reasoning steps and tool results
- **Semantic Memory**: Vector-based knowledge storage and retrieval

PERFORMANCE OPTIMIZATIONS:
=========================

1. **Smart Tool Selection**: Context-aware tool prioritization
2. **Caching Strategy**: Intelligent result caching to avoid redundant calls
3. **Parallel Execution**: Where possible, execute tools concurrently
4. **Resource Management**: Memory and computation resource optimization
5. **Timeout Handling**: Graceful handling of slow or unresponsive tools

MULTILINGUAL CAPABILITIES:
=========================

- **Language Detection**: Automatic detection of user language
- **Contextual Responses**: Culturally appropriate responses in the user's detected language
- **Code-Switching**: Natural handling of mixed-language inputs
- **Localized Tool Usage**: Language-specific tool selection and parameterization

ERROR HANDLING STRATEGY:
=======================

Comprehensive error handling with multiple fallback mechanisms:
1. **Tool Failure Recovery**: Alternative tool selection on failure
2. **Memory Corruption Handling**: State recovery and cleanup
3. **Timeout Management**: Graceful handling of long-running operations
4. **Partial Result Processing**: Useful output even from incomplete operations

INTEGRATION PATTERNS:
====================

Seamless integration with BPAZ-Agentic-Platform ecosystem:
- **LangGraph Compatibility**: Full state management integration
- **LangSmith Tracing**: Comprehensive observability and debugging
- **Vector Store Integration**: Advanced RAG capabilities
- **Custom Node Connectivity**: Easy integration with custom business logic

VERSION: 2.1.0
LAST_UPDATED: 2025-07-26
"""

from ..base import ProcessorNode, NodeInput, NodeType, NodeOutput
from typing import Dict, Any, Sequence
from langchain_core.runnables import Runnable, RunnableLambda
from langchain_core.language_models import BaseLanguageModel
from langchain_core.tools import BaseTool
from langchain_core.prompts import PromptTemplate
from langchain_core.memory import BaseMemory
from langchain_core.retrievers import BaseRetriever
from langchain.agents import AgentExecutor, create_react_agent
# Manual retriever tool creation since langchain-community import is not working
from langchain_core.tools import Tool
import re
import sys
import os
import locale

# ================================================================================
# LANGUAGE DETECTION AND LOCALIZATION SYSTEM
# ================================================================================

def detect_language(text: str) -> str:
    """
    Comprehensive multilingual language detection supporting 20+ languages.
    Uses character sets, common words, and statistical patterns for accurate detection.

    Detection Strategy:
    1. Character set analysis (primary indicator)
    2. Language-specific word patterns and n-grams
    3. Statistical scoring with confidence thresholds
    4. Fallback mechanisms for edge cases
    5. Support for mixed-language content

    Supported Languages:
    - English (en), German (de), French (fr), Spanish (es)
    - Italian (it), Portuguese (pt), Dutch (nl), Russian (ru), Arabic (ar)
    - Chinese (zh), Japanese (ja), Korean (ko), Hindi (hi), Persian (fa)
    - Greek (el), Polish (pl), Czech (cs), Romanian (ro), Hungarian (hu)

    Args:
        text (str): Input text to analyze

    Returns:
        str: ISO 639-1 language code (e.g., 'en', 'de', 'fr', etc.)
    """
    if not text or not text.strip():
        return 'en'  # Default to English for empty input

    text_lower = text.lower().strip()

    # Language detection patterns with character sets and common words
    language_patterns = {
        'en': {  # English
            'charset': r'[a-zA-Z]',
            'high_priority': [
                r'\b(the|and|or|but|because|with|for|from|this|that)\b',
                r'\b(hello|hi|dear|thank|please|help|assist|welcome)\b',
                r'\b(customer|product|project|company|service|information)\b'
            ],
            'medium_priority': [
                r'\b(what|how|who|when|where|why|which|which)\b',
                r'\b(i|you|we|they|he|she|it|me|us|them)\b',
                r'\b(is|are|was|were|will|would|can|could|should)\b'
            ]
        },
        'de': {  # German
            'charset': r'[Ã¤Ã¶Ã¼ÃŸÃ„Ã–ÃœÃŸ]',
            'high_priority': [
                r'\b(und|oder|aber|weil|mit|fÃ¼r|von|das|der|die|den)\b',
                r'\b(hallo|hallo|danke|bitte|hilfe|unterstÃ¼tzung|willkommen)\b',
                r'\b(kunde|produkt|projekt|firma|unternehmen|dienst|information)\b'
            ],
            'medium_priority': [
                r'\b(was|wie|wer|wann|wo|warum|welche)\b',
                r'\b(ich|du|sie|wir|ihr|er|sie|es|mich|dich|uns)\b'
            ]
        },
        'fr': {  # French
            'charset': r'[Ã©Ã¨ÃªÃ Ã¢Ã¹Ã»Ã¯Ã®Ã´Ã§Ã‰ÃˆÃŠÃ€Ã‚Ã™Ã›ÃÃŽÃ”Ã‡]',
            'high_priority': [
                r'\b(et|ou|mais|parce|avec|pour|de|le|la|les|un|une)\b',
                r'\b(bonjour|salut|merci|s\'il|vous|plaÃ®t|aide|bienvenue)\b',
                r'\b(client|produit|projet|entreprise|service|information)\b'
            ],
            'medium_priority': [
                r'\b(quoi|comment|qui|quand|oÃ¹|pourquoi|quel|quelle)\b',
                r'\b(je|tu|il|elle|nous|vous|ils|elles|me|te)\b'
            ]
        },
        'es': {  # Spanish
            'charset': r'[Ã±Ã¡Ã©Ã­Ã³ÃºÃ¼Ã‘ÃÃ‰ÃÃ“ÃšÃœ]',
            'high_priority': [
                r'\b(y|o|pero|porque|con|para|de|el|la|los|las|un|una)\b',
                r'\b(hola|gracias|por|favor|ayuda|bienvenido|informaciÃ³n)\b',
                r'\b(cliente|producto|proyecto|empresa|servicio|informaciÃ³n)\b'
            ],
            'medium_priority': [
                r'\b(quÃ©|cÃ³mo|quiÃ©n|cuÃ¡ndo|dÃ³nde|por|quÃ©|cuÃ¡l)\b',
                r'\b(yo|tÃº|Ã©l|ella|nosotros|ustedes|ellos|ellas)\b'
            ]
        },
        'it': {  # Italian
            'charset': r'[Ã Ã¨Ã©Ã¬Ã­Ã®Ã³Ã²Ã¹Ã§Ã€ÃˆÃ‰ÃŒÃÃŽÃ“Ã’Ã™Ã‡]',
            'high_priority': [
                r'\b(e|o|ma|perchÃ©|con|per|di|il|la|i|le|un|una)\b',
                r'\b(ciao|grazie|per|favore|aiuto|benvenuto|informazione)\b',
                r'\b(cliente|prodotto|progetto|azienda|servizio|informazione)\b'
            ],
            'medium_priority': [
                r'\b(che|come|chi|quando|dove|perchÃ©|quale)\b',
                r'\b(io|tu|lui|lei|noi|voi|loro|me|te|ci)\b'
            ]
        },
        'pt': {  # Portuguese
            'charset': r'[Ã£Ã¡Ã©Ã­Ã³ÃºÃ Ã¢ÃªÃ´Ã§ÃƒÃÃ‰ÃÃ“ÃšÃ€Ã‚ÃŠÃ”Ã‡]',
            'high_priority': [
                r'\b(e|ou|mas|porque|com|para|de|o|a|os|as|um|uma)\b',
                r'\b(olÃ¡|obrigado|por|favor|ajuda|bem-vindo|informaÃ§Ã£o)\b',
                r'\b(cliente|produto|projeto|empresa|serviÃ§o|informaÃ§Ã£o)\b'
            ],
            'medium_priority': [
                r'\b(o|que|como|quem|quando|onde|por|que|qual)\b',
                r'\b(eu|tu|ele|ela|nÃ³s|vocÃªs|eles|elas|me|te)\b'
            ]
        },
        'ru': {  # Russian
            'charset': r'[Ð°-ÑÐ-Ð¯Ñ‘Ð]',
            'high_priority': [
                r'\b(Ð¸|Ð¸Ð»Ð¸|Ð½Ð¾|Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ|Ñ‡Ñ‚Ð¾|Ñ|Ð´Ð»Ñ|Ð¸Ð·|ÑÑ‚Ð¾|ÑÑ‚Ð¾Ñ‚|ÑÑ‚Ð°|ÑÑ‚Ð¸)\b',
                r'\b(Ð¿Ñ€Ð¸Ð²ÐµÑ‚|ÑÐ¿Ð°ÑÐ¸Ð±Ð¾|Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°|Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒ|Ð´Ð¾Ð±Ñ€Ð¾|Ð¿Ð¾Ð¶Ð°Ð»Ð¾Ð²Ð°Ñ‚ÑŒ)\b',
                r'\b(ÐºÐ»Ð¸ÐµÐ½Ñ‚|Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚|Ð¿Ñ€Ð¾ÐµÐºÑ‚|ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ñ|ÑƒÑÐ»ÑƒÐ³Ð°|Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ)\b'
            ],
            'medium_priority': [
                r'\b(Ñ‡Ñ‚Ð¾|ÐºÐ°Ðº|ÐºÑ‚Ð¾|ÐºÐ¾Ð³Ð´Ð°|Ð³Ð´Ðµ|Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ|ÐºÐ°ÐºÐ¾Ð¹)\b',
                r'\b(Ñ|Ñ‚Ñ‹|Ð¾Ð½|Ð¾Ð½Ð°|Ð¼Ñ‹|Ð²Ñ‹|Ð¾Ð½Ð¸|Ð¼ÐµÐ½Ñ|Ñ‚ÐµÐ±Ñ|Ð½Ð°Ñ)\b'
            ]
        },
        'ar': {  # Arabic
            'charset': r'[\u0600-\u06FF]',
            'high_priority': [
                r'\b(Ùˆ|Ø£Ùˆ|Ù„ÙƒÙ†|Ù„Ø£Ù†|Ù…Ø¹|Ù…Ù†|ÙÙŠ|Ù‡Ø°Ø§|Ù‡Ø°Ù‡|Ù‡Ø¤Ù„Ø§Ø¡)\b',
                r'\b(Ù…Ø±Ø­Ø¨Ø§|Ø´ÙƒØ±Ø§|Ù…Ù†|ÙØ¶Ù„Ùƒ|Ù…Ø³Ø§Ø¹Ø¯Ø©|Ø£Ù‡Ù„Ø§|Ø¨Ùƒ|Ù…Ø¹Ù„ÙˆÙ…Ø§Øª)\b',
                r'\b(Ø¹Ù…ÙŠÙ„|Ù…Ù†ØªØ¬|Ù…Ø´Ø±ÙˆØ¹|Ø´Ø±ÙƒØ©|Ø®Ø¯Ù…Ø©|Ù…Ø¹Ù„ÙˆÙ…Ø§Øª)\b'
            ],
            'medium_priority': [
                r'\b(Ù…Ø§|ÙƒÙŠÙ|Ù…Ù†|Ù…ØªÙ‰|Ø£ÙŠÙ†|Ù„Ù…Ø§Ø°Ø§|Ø£ÙŠ)\b',
                r'\b(Ø£Ù†Ø§|Ø£Ù†Øª|Ù‡Ùˆ|Ù‡ÙŠ|Ù†Ø­Ù†|Ø£Ù†ØªÙ…|Ù‡Ù…|Ù‡ÙŠ|Ù†ÙŠ)\b'
            ]
        },
        'zh': {  # Chinese
            'charset': r'[\u4e00-\u9fff]',
            'high_priority': [
                r'\b(å’Œ|æˆ–|ä½†|å› ä¸º|ä¸Ž|ä¸º|ä»Ž|çš„|è¿™|é‚£|ä¸ª|æ˜¯)\b',
                r'\b(ä½ å¥½|è°¢è°¢|è¯·|å¸®åŠ©|æ¬¢è¿Ž|ä¿¡æ¯|æœåŠ¡)\b',
                r'\b(å®¢æˆ·|äº§å“|é¡¹ç›®|å…¬å¸|æœåŠ¡|ä¿¡æ¯)\b'
            ],
            'medium_priority': [
                r'\b(ä»€ä¹ˆ|å¦‚ä½•|è°|ä½•æ—¶|å“ªé‡Œ|ä¸ºä»€ä¹ˆ|å“ªä¸ª)\b',
                r'\b(æˆ‘|ä½ |ä»–|å¥¹|æˆ‘ä»¬|ä½ ä»¬|ä»–ä»¬|å¥¹ä»¬)\b'
            ]
        },
        'ja': {  # Japanese
            'charset': r'[\u3040-\u30ff\u3400-\u4dbf\u4e00-\u9fff]',
            'high_priority': [
                r'\b(ã¨|ã‹|ã—ã‹ã—|ãªãœãªã‚‰|ã¨|ã®|ã“ã‚Œ|ãã‚Œ|ã®|ã§ã™|ã¾ã™)\b',
                r'\b(ã“ã‚“ã«ã¡ã¯|ã‚ã‚ŠãŒã¨ã†|ãã ã•ã„|ãŠã­ãŒã„ã—ã¾ã™|åŠ©ã‘|ã‚ˆã†ã“ã)\b',
                r'\b(ãŠå®¢æ§˜|è£½å“|ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ|ä¼šç¤¾|ã‚µãƒ¼ãƒ“ã‚¹|æƒ…å ±)\b'
            ],
            'medium_priority': [
                r'\b(ä½•|ã©ã†|èª°|ã„ã¤|ã©ã“|ãªãœ|ã©ã®)\b',
                r'\b(ç§|ã‚ãªãŸ|å½¼|å½¼å¥³|ç§ãŸã¡|ã‚ãªãŸãŸã¡|å½¼ã‚‰|å½¼å¥³ã‚‰)\b'
            ]
        },
        'ko': {  # Korean
            'charset': r'[\uac00-\ud7af]',
            'high_priority': [
                r'\b(ê·¸ë¦¬ê³ |ë˜ëŠ”|í•˜ì§€ë§Œ|ì™œëƒí•˜ë©´|ê³¼|ìœ„í•´|ì˜|ì´|ê·¸|ì €|ìž…ë‹ˆë‹¤)\b',
                r'\b(ì•ˆë…•í•˜ì„¸ìš”|ê°ì‚¬í•©ë‹ˆë‹¤|ì£¼ì„¸ìš”|ë„ì™€ì£¼ì„¸ìš”|í™˜ì˜í•©ë‹ˆë‹¤|ì •ë³´)\b',
                r'\b(ê³ ê°|ì œí’ˆ|í”„ë¡œì íŠ¸|íšŒì‚¬|ì„œë¹„ìŠ¤|ì •ë³´)\b'
            ],
            'medium_priority': [
                r'\b(ë¬´ì—‡|ì–´ë–»ê²Œ|ëˆ„ê°€|ì–¸ì œ|ì–´ë””|ì™œ|ì–´ëŠ)\b',
                r'\b(ë‚˜|ë„ˆ|ê·¸|ê·¸ë…€|ìš°ë¦¬|ë„ˆí¬|ê·¸ë“¤|ê·¸ë…€ë“¤|ë‚˜|ë„ˆ)\b'
            ]
        },
        'hi': {  # Hindi
            'charset': r'[\u0900-\u097f]',
            'high_priority': [
                r'\b(à¤”à¤°|à¤¯à¤¾|à¤²à¥‡à¤•à¤¿à¤¨|à¤•à¥à¤¯à¥‹à¤‚à¤•à¤¿|à¤•à¥‡|à¤²à¤¿à¤|à¤¸à¥‡|à¤•à¤¾|à¤•à¤¿|à¤¯à¥‡|à¤µà¤¹|à¤¹à¥ˆ)\b',
                r'\b(à¤¨à¤®à¤¸à¥à¤¤à¥‡|à¤§à¤¨à¥à¤¯à¤µà¤¾à¤¦|à¤•à¥ƒà¤ªà¤¯à¤¾|à¤®à¤¦à¤¦|à¤¸à¥à¤µà¤¾à¤—à¤¤|à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€)\b',
                r'\b(à¤—à¥à¤°à¤¾à¤¹à¤•|à¤‰à¤¤à¥à¤ªà¤¾à¤¦|à¤ªà¤°à¤¿à¤¯à¥‹à¤œà¤¨à¤¾|à¤•à¤‚à¤ªà¤¨à¥€|à¤¸à¥‡à¤µà¤¾|à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€)\b'
            ],
            'medium_priority': [
                r'\b(à¤•à¥à¤¯à¤¾|à¤•à¥ˆà¤¸à¥‡|à¤•à¥Œà¤¨|à¤•à¤¬|à¤•à¤¹à¤¾à¤|à¤•à¥à¤¯à¥‹à¤‚|à¤•à¥Œà¤¨)\b',
                r'\b(à¤®à¥ˆà¤‚|à¤¤à¥‚|à¤µà¤¹|à¤µà¤¹|à¤¹à¤®|à¤†à¤ª|à¤µà¥‡|à¤µà¥‡|à¤®à¥à¤à¥‡|à¤¤à¥à¤à¥‡)\b'
            ]
        },
        'fa': {  # Persian/Farsi
            'charset': r'[\u0600-\u06FF]',
            'high_priority': [
                r'\b(Ùˆ|ÛŒØ§|Ø§Ù…Ø§|Ú†Ø±Ø§|Ø¨Ø§|Ø¨Ø±Ø§ÛŒ|Ø§Ø²|Ø§ÛŒÙ†|Ø¢Ù†|Ø¢Ù†Ù‡Ø§|Ø§Ø³Øª)\b',
                r'\b(Ø³Ù„Ø§Ù…|Ù…Ø±Ø³ÛŒ|Ù„Ø·ÙØ§|Ú©Ù…Ú©|Ø®ÙˆØ´|Ø¢Ù…Ø¯ÛŒØ¯|Ø§Ø·Ù„Ø§Ø¹Ø§Øª)\b',
                r'\b(Ù…Ø´ØªØ±ÛŒ|Ù…Ø­ØµÙˆÙ„|Ù¾Ø±ÙˆÚ˜Ù‡|Ø´Ø±Ú©Øª|Ø®Ø¯Ù…Ø§Øª|Ø§Ø·Ù„Ø§Ø¹Ø§Øª)\b'
            ],
            'medium_priority': [
                r'\b(Ú†Ù‡|Ú†Ú¯ÙˆÙ†Ù‡|Ú©ÛŒ|Ú©ÛŒ|Ú©Ø¬Ø§|Ú†Ø±Ø§|Ú©Ø¯Ø§Ù…ÛŒÚ©)\b',
                r'\b(Ù…Ù†|ØªÙˆ|Ø§Ùˆ|Ø§Ùˆ|Ù…Ø§|Ø´Ù…Ø§|Ø¢Ù†Ù‡Ø§|Ø¢Ù†Ù‡Ø§|Ù…Ø±Ø§|ØªØ±Ø§)\b'
            ]
        }
    }

    # Initialize scores for all languages
    scores = {lang: 0 for lang in language_patterns.keys()}

    # Character set analysis (highest priority)
    for lang, patterns in language_patterns.items():
        if 'charset' in patterns and re.search(patterns['charset'], text):
            if lang in ['ar', 'fa', 'ru']:  # RTL languages get higher priority
                scores[lang] += 8
            elif lang in ['zh', 'ja', 'ko', 'hi']:  # CJK and Devanagari
                scores[lang] += 6
            else:
                scores[lang] += 4

    # Pattern matching analysis
    for lang, patterns in language_patterns.items():
        # High priority patterns
        for pattern in patterns.get('high_priority', []):
            if re.search(pattern, text_lower):
                scores[lang] += 3

        # Medium priority patterns
        for pattern in patterns.get('medium_priority', []):
            if re.search(pattern, text_lower):
                scores[lang] += 1

    # English business terms
    english_business_terms = [
        'customer', 'product', 'project', 'company', 'service', 'information',
        'help', 'support', 'question', 'please', 'thank', 'welcome'
    ]
    for term in english_business_terms:
        if term in text_lower:
            scores['en'] += 1

    # Find the language with highest score
    max_score = max(scores.values())
    if max_score == 0:
        return 'en'  # Default to English if no patterns match

    # Get all languages with maximum score
    top_languages = [lang for lang, score in scores.items() if score == max_score]

    # If there's a tie, use tie-breaker logic
    if len(top_languages) > 1:
        # Prefer languages with unique character sets
        for lang in ['de', 'fr', 'es', 'it', 'pt', 'ru', 'ar', 'zh', 'ja', 'ko', 'hi', 'fa']:
            if lang in top_languages:
                return lang

        # If still tied, prefer English as fallback
        if 'en' in top_languages:
            return 'en'

        # Otherwise, return the first one alphabetically
        return sorted(top_languages)[0]

    return top_languages[0]

def get_language_specific_prompt(language_code: str) -> str:
    """
    Returns comprehensive language-specific system prompt with mandatory language enforcement
    supporting 15+ languages with their unique characteristics and cultural contexts.

    Args:
        language_code (str): ISO 639-1 language code (e.g., 'en', 'tr', 'de', 'fr', etc.)

    Returns:
        str: Language-specific system prompt with cultural adaptation
    """

    # Universal language enforcement rules (always included)
    universal_rules = """
ðŸ”´ MANDATORY LANGUAGE RULE: Always answer in the same language that the user used in the question. ðŸ”´
"""

    english_prompt = f"""
{universal_rules}

You are an expert AI assistant operating on the BPAZ-Agentic-Platform platform. Always respond in clear, professional English regardless of the input language.

RULES:
1. Provide answers exclusively in English, even if the user writes in another language.
2. Never mix multiple languages in a single reply.
3. Maintain consistency, clarity, and professionalism throughout the conversation.

CONVERSATION HISTORY USAGE:
- Review previous turns and respond with full contextual awareness.
- Use the conversation history to clarify references and pronouns.
- Preserve important context from earlier exchanges when formulating answers.

TOOL USAGE RULES:
- Use tools first whenever they can answer the question.
- Call tools for documents, people, or detailed information.
- Do not trigger tools for casual chit-chat (e.g., greetings).
- Present tool results in clear, natural English.
- If tools cannot provide an answer, help with general knowledge.

RESPONSE STYLE:
- Use a friendly, professional tone in English.
- Explain complex topics clearly and step-by-step.
- Match the technical depth to the user's skill level.
- Emphasize clarity, empathy, and accuracy in every reply.

LANGUAGE DETECTION:
- Detect the user's language, but always reply in English.
- When encountering unsupported characters, sanitise them before responding.
- If unsure how to interpret the input, ask clarifying questions in English.
"""

    return english_prompt

# ================================================================================
# RETRIEVER TOOL FACTORY - ADVANCED RAG INTEGRATION
# ================================================================================

def create_retriever_tool(name: str, description: str, retriever: BaseRetriever) -> Tool:
    """
    Advanced Retriever Tool Factory for RAG Integration
    =================================================
    
    Creates a sophisticated tool that wraps a LangChain BaseRetriever for use in
    ReactAgent workflows. This factory provides enterprise-grade features including
    result formatting, error handling, performance optimization, and multilingual support.
    
    FEATURES:
    ========
    
    1. **Intelligent Result Formatting**: Structures retriever results for optimal agent consumption
    2. **Performance Optimization**: Limits results and content length for efficiency
    3. **Error Resilience**: Comprehensive error handling with informative fallbacks
    4. **Content Truncation**: Smart content trimming to prevent token overflow
    5. **Multilingual Support**: Works seamlessly with English and other supported languages
    
    DESIGN PHILOSOPHY:
    =================
    
    - **Agent-Centric**: Output optimized for agent reasoning and decision making
    - **Performance-First**: Balanced between comprehensiveness and speed
    - **Error-Tolerant**: Never fails completely, always provides useful feedback
    - **Context-Aware**: Understands the broader workflow context
    
    Args:
        name (str): Tool identifier for agent reference (should be descriptive)
        description (str): Detailed description of tool capabilities for agent planning
        retriever (BaseRetriever): LangChain retriever instance (vector store, BM25, etc.)
    
    Returns:
        Tool: LangChain Tool instance ready for agent integration
    
    EXAMPLE USAGE:
    =============
    
    ```python
    # Create a retriever tool from a vector store
    vector_retriever = vector_store.as_retriever(search_kwargs={"k": 10})
    rag_tool = create_retriever_tool(
        name="knowledge_search",
        description="Search company knowledge base for relevant information",
        retriever=vector_retriever
    )
    
    # Use in ReactAgent
    agent = ReactAgentNode()
    result = agent.execute(
        inputs={"input": "What is our refund policy?"},
        connected_nodes={"llm": llm, "tools": [rag_tool]}
    )
    ```
    
    PERFORMANCE CHARACTERISTICS:
    ===========================
    
    - **Result Limit**: Maximum 5 documents to prevent information overload
    - **Content Limit**: 500 characters per document with smart truncation
    - **Error Recovery**: Graceful handling of retriever failures
    - **Memory Efficiency**: Optimized string formatting to minimize memory usage
    """
    
    def retrieve_func(query: str) -> str:
        """
        Enhanced retrieval function that provides comprehensive, structured results
        optimized for agent consumption and decision making.
        """
        try:
            # Perform the retrieval
            docs = retriever.get_relevant_documents(query)
            
            if not docs:
                return f"""ðŸ” SEARCH RESULTS
Query: '{query}' did not return any documents.

ðŸ“Š SEARCH SUMMARY:
- The lookup completed successfully but no relevant documents were found.
- Try refining the query with more specific keywords.
- Alternatively, rephrase the request for a broader answer."""
            
            # Limit results for performance (max 5 documents)
            limited_docs = docs[:5]
            
            # Format results for agent consumption
            result_parts = [
                "ðŸ” SEARCH RESULTS",
                f"Total documents found: {len(docs)}",
                f"Documents shown: {len(limited_docs)}",
                ""
            ]
            
            for i, doc in enumerate(limited_docs, 1):
                # Get content and metadata
                content = doc.page_content
                metadata = doc.metadata if hasattr(doc, 'metadata') else {}
                
                # Smart content truncation (500 chars max per doc)
                if len(content) > 500:
                    content = content[:500] + "..."
                
                # Extract source information
                source = metadata.get('source', 'unknown')
                if isinstance(source, str) and len(source) > 50:
                    source = source[-50:]  # Show last 50 chars for long paths
                
                result_parts.extend(
                    [
                        f"=== DOCUMENT {i} === (Source: {source})",
                        "CONTENT:",
                        content,
                        "",
                        "---",
                        "",
                    ]
                )
            
            result_parts.extend(
                [
                    "",
                    "ðŸ“Š SEARCH SUMMARY:",
                    f"- These documents are the most relevant results for '{query}'.",
                    "- The agent will analyse each document for detailed insights.",
                    "- Documents are ordered by relevance.",
                ]
            )
            
            return "\n".join(result_parts)
            
        except Exception as e:
            error_msg = str(e)
            return f"""ðŸ” SEARCH RESULTS
Query: '{query}' encountered a technical error during retrieval.

âš ï¸ ERROR DETAILS:
{error_msg}

ðŸ“Š SEARCH SUMMARY:
- The search could not be completed because of the error above.
- Please try again with different keywords.
- If the issue persists, contact the system administrator."""
    
    # Create and return the configured tool
    return Tool(
        name=name,
        description=description,
        func=retrieve_func
    )

# ================================================================================
# REACTAGENT NODE - THE ORCHESTRATION BRAIN OF BPAZ-AGENTIC-PLATFORM
# ================================================================================

class ReactAgentNode(ProcessorNode):
    """
    BPAZ-Agentic-Platform ReactAgent - Advanced AI Agent Orchestration Engine
    ===========================================================
    
    The ReactAgentNode is the crown jewel of the BPAZ-Agentic-Platform platform, representing the
    culmination of advanced AI agent architecture, multilingual intelligence, and
    enterprise-grade orchestration capabilities. Built upon LangChain's proven ReAct
    framework, it transcends traditional chatbot limitations to deliver sophisticated,
    reasoning-driven AI interactions.
    
    CORE PHILOSOPHY:
    ===============
    
    "Intelligence through Reasoning and Action"
    
    Unlike simple question-answer systems, the ReactAgent embodies true intelligence
    through its ability to:
    1. **Reason** about complex problems and break them into actionable steps
    2. **Act** by strategically selecting and executing appropriate tools
    3. **Observe** the results and adapt its approach dynamically
    4. **Learn** from each interaction to improve future performance
    
    ARCHITECTURAL EXCELLENCE:
    ========================
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                REACTAGENT ARCHITECTURE                      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                             â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
    â”‚  â”‚   REASON    â”‚ -> â”‚    ACT      â”‚ -> â”‚  OBSERVE    â”‚     â”‚
    â”‚  â”‚             â”‚    â”‚             â”‚    â”‚             â”‚     â”‚
    â”‚  â”‚ â€¢ Analyze   â”‚    â”‚ â€¢ Select    â”‚    â”‚ â€¢ Process   â”‚     â”‚
    â”‚  â”‚ â€¢ Plan      â”‚    â”‚ â€¢ Execute   â”‚    â”‚ â€¢ Evaluate  â”‚     â”‚
    â”‚  â”‚ â€¢ Strategy  â”‚    â”‚ â€¢ Monitor   â”‚    â”‚ â€¢ Learn     â”‚     â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
    â”‚           ^                                      â”‚          â”‚
    â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
    â”‚                         FEEDBACK LOOP                       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ENTERPRISE FEATURES:
    ===================
    
    1. **Multilingual Intelligence**: 
       - Native English processing with cultural context awareness
       - Seamless code-switching and contextual language adaptation
       - Localized reasoning patterns optimized for each language
    
    2. **Advanced Tool Orchestration**:
       - Dynamic tool selection based on context and capability analysis
       - Parallel tool execution where applicable for performance optimization
       - Intelligent fallback mechanisms for tool failures
       - Comprehensive tool result analysis and integration
    
    3. **Memory Architecture**:
       - Multi-layered memory system (short-term, long-term, working, semantic)
       - Conversation context preservation across sessions
       - Adaptive memory management with relevance scoring
       - Privacy-aware memory handling with data protection
    
    4. **Performance Optimization**:
       - Smart iteration limits to prevent infinite loops
       - Token usage optimization through strategic content truncation
       - Caching mechanisms for frequently accessed information
       - Resource-aware execution with graceful degradation
    
    5. **Error Resilience**:
       - Comprehensive error handling with multiple recovery strategies
       - Graceful degradation when tools or services are unavailable
       - Detailed error reporting for debugging and improvement
       - User-friendly error communication without technical jargon
    
    REASONING CAPABILITIES:
    ======================
    
    The ReactAgent demonstrates advanced reasoning through:
    
    - **Causal Reasoning**: Understanding cause-and-effect relationships
    - **Temporal Reasoning**: Managing time-based information and sequences
    - **Spatial Reasoning**: Processing location and geometric information
    - **Abstract Reasoning**: Handling concepts, metaphors, and complex ideas
    - **Social Reasoning**: Understanding human emotions, intentions, and context
    
    TOOL INTEGRATION MATRIX:
    =======================
    
    â”‚ Tool Type        â”‚ Purpose                    â”‚ Integration Level â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Search Tools    â”‚ Information retrieval     â”‚ Native           â”‚
    â”‚ RAG Tools       â”‚ Document-based Q&A        â”‚ Advanced         â”‚
    â”‚ API Tools       â”‚ External service access   â”‚ Standard         â”‚
    â”‚ Processing      â”‚ Data transformation       â”‚ Standard         â”‚
    â”‚ Memory Tools    â”‚ Context management        â”‚ Deep             â”‚
    â”‚ Custom Tools    â”‚ Business logic            â”‚ Extensible       â”‚
    
    MULTILINGUAL OPTIMIZATION:
    =========================
    
    English Language Features:
    - International variant support
    - Technical terminology handling
    - Cultural sensitivity awareness
    - Professional communication styles
    
    Additional Language Features:
    - Localised response tone and etiquette
    - Automatic handling of character sets and directionality
    - Context-aware translation of tool outputs
    - Consistent formatting across supported languages
    
    PERFORMANCE METRICS:
    ===================
    
    Target Performance Characteristics:
    - Response Time: < 3 seconds for simple queries
    - Tool Execution: < 10 seconds for complex multi-tool workflows
    - Memory Efficiency: < 100MB working memory per session
    - Accuracy: > 95% for factual questions with available information
    - User Satisfaction: > 4.8/5.0 based on interaction quality
    
    INTEGRATION PATTERNS:
    ====================
    
    Standard Integration:
    ```python
    # Basic agent setup
    agent = ReactAgentNode()
    result = agent.execute(
        inputs={
            "input": "Analyze the quarterly sales data and provide insights",
            "max_iterations": 5,
            "system_prompt": "You are a business analyst assistant"
        },
        connected_nodes={
            "llm": openai_llm,
            "tools": [search_tool, calculator_tool, chart_tool],
            "memory": conversation_memory
        }
    )
    ```
    
    Advanced RAG Integration:
    ```python
    # RAG-enabled agent
    rag_retriever = vector_store.as_retriever()
    rag_tool = create_retriever_tool(
        name="knowledge_search",
        description="Search company knowledge base",
        retriever=rag_retriever
    )
    
    agent = ReactAgentNode()
    result = agent.execute(
        inputs={"input": "What's our policy on remote work?"},
        connected_nodes={
            "llm": llm,
            "tools": [rag_tool, hr_api_tool],
            "memory": memory
        }
    )
    ```
    
    SECURITY AND PRIVACY:
    ====================
    
    - Input sanitization to prevent injection attacks
    - Output filtering to prevent sensitive information leakage
    - Tool permission management with role-based access
    - Conversation logging with privacy controls
    - Compliance with GDPR, CCPA, and other privacy regulations
    
    MONITORING AND OBSERVABILITY:
    ============================
    
    - LangSmith integration for comprehensive tracing
    - Performance metrics collection and analysis
    - Error tracking and alerting systems
    - User interaction analytics for continuous improvement
    - A/B testing framework for prompt optimization
    
    VERSION HISTORY:
    ===============
    
    v2.1.0 (Current):
    - Enhanced multilingual support with improved English-first defaults
    - Advanced retriever tool integration
    - Improved error handling and recovery mechanisms
    - Performance optimizations and memory management
    
    v2.0.0:
    - Complete rewrite with ProcessorNode architecture
    - LangGraph integration for complex workflows
    - Advanced prompt engineering with cultural context
    
    v1.x:
    - Initial ReactAgent implementation
    - Basic tool integration and memory support
    
    VERSION: 2.1.0
    LAST_UPDATED: 2025-07-26
    """
    
    def __init__(self):
        super().__init__()
        self._metadata = {
            "name": "Agent",
            "display_name": "Agent",
            "description": "Orchestrates LLM, tools, and memory for complex, multi-step tasks.",
            "category": "Agents",
            "node_type": NodeType.PROCESSOR,
            "inputs": [
                NodeInput(name="input", type="string", required=True, description="The user's input to the agent."),
                NodeInput(name="llm", type="BaseLanguageModel", required=True, is_connection=True, description="The language model that the agent will use."),
                NodeInput(name="tools", type="Sequence[BaseTool]", required=False, is_connection=True, description="The tools that the agent can use."),
                NodeInput(name="memory", type="BaseMemory", required=False, is_connection=True, description="The memory that the agent can use."),
                NodeInput(name="max_iterations", type="int", default=10, description="The maximum number of iterations the agent can perform."),
                NodeInput(name="system_prompt", type="str", default="You are an expert AI assistant specialized in providing detailed, step-by-step guidance and comprehensive answers. You excel at breaking down complex topics into clear, actionable instructions.", description="The system prompt for the agent."),
                NodeInput(name="prompt_instructions", type="str", required=False,
                         description="Custom prompt instructions for the agent. If not provided, uses smart orchestration defaults.",
                         default=""),
            ],
            "outputs": [NodeOutput(name="output", type="str", description="The final output from the agent.")]
        }

    def execute(self, inputs: Dict[str, Any], connected_nodes: Dict[str, Runnable]) -> Runnable:
        """
        Sets up and returns a RunnableLambda that executes the agent with dynamic language detection.
        """
        def agent_executor_lambda(runtime_inputs: dict) -> dict:
            # ðŸ”§ Ensure stdout/stderr use UTF-8 encoding
            try:
                # Force UTF-8 encoding for all string operations
                if hasattr(sys.stdout, 'reconfigure'):
                    sys.stdout.reconfigure(encoding='utf-8')
                if hasattr(sys.stderr, 'reconfigure'):
                    sys.stderr.reconfigure(encoding='utf-8')

                # Set environment variables for UTF-8 (Docker-compatible)
                os.environ.setdefault('PYTHONIOENCODING', 'utf-8')
                os.environ.setdefault('LANG', 'C.UTF-8')
                os.environ.setdefault('LC_ALL', 'C.UTF-8')

                # Docker containers handle UTF-8 by default, no locale setup needed
                # This ensures UTF-8 characters work without system-specific locale requirements

                print(f"[DEBUG] Encoding setup completed - Default: {sys.getdefaultencoding()}")

            except Exception as encoding_error:
                print(f"[WARNING] Encoding setup failed: {encoding_error}")

            # Debug connection information
            print(f"[DEBUG] Agent connected_nodes keys: {list(connected_nodes.keys())}")
            print(f"[DEBUG] Agent connected_nodes types: {[(k, type(v)) for k, v in connected_nodes.items()]}")

            llm = connected_nodes.get("llm")
            tools = connected_nodes.get("tools")
            memory = connected_nodes.get("memory")

            # Enhanced LLM validation with better error reporting
            print(f"[DEBUG] LLM received: {type(llm)}")
            if llm is None:
                available_connections = list(connected_nodes.keys())
                raise ValueError(
                    f"A valid LLM connection is required. "
                    f"Available connections: {available_connections}. "
                    f"Make sure to connect an OpenAI Chat node to the 'llm' input of this Agent."
                )

            if not isinstance(llm, BaseLanguageModel):
                raise ValueError(
                    f"Connected LLM must be a BaseLanguageModel instance, got {type(llm)}. "
                    f"Ensure the OpenAI Chat node is properly configured and connected."
                )

            tools_list = self._prepare_tools(tools)

            # Dynamic language detection from user input
            user_input = ""
            if isinstance(runtime_inputs, str):
                user_input = runtime_inputs
            elif isinstance(runtime_inputs, dict):
                user_input = runtime_inputs.get("input", inputs.get("input", ""))
            else:
                user_input = inputs.get("input", "")

            # Detect user's language with robust Unicode handling
            try:
                detected_language = detect_language(user_input)
                print(f"[LANGUAGE DETECTION] User input: '{user_input[:50]}...' -> Detected: {detected_language}")
            except UnicodeEncodeError as lang_error:
                print(f"[WARNING] Language detection encoding error: {lang_error}")
                detected_language = 'en'
                print(f"[LANGUAGE DETECTION] Defaulting to English due to encoding error")

            # Create language-specific prompt
            agent_prompt = self._create_language_specific_prompt(tools_list, detected_language)

            agent = create_react_agent(llm, tools_list, agent_prompt)

            # Get max_iterations from inputs (user configuration) with proper fallback
            max_iterations = inputs.get("max_iterations")
            if max_iterations is None:
                max_iterations = self.user_data.get("max_iterations", 10)  # Increased default for more detailed processing
            
            print(f"[DEBUG] Max iterations configured: {max_iterations}")
            
            # Build executor config with enhanced settings for detailed responses
            executor_config = {
                "agent": agent,
                "tools": tools_list,
                "verbose": True, # Essential for real-time debugging
                "handle_parsing_errors": True,  # Use boolean instead of string
                "max_iterations": max_iterations,
                "return_intermediate_steps": True,  # Capture tool usage for debugging
                "max_execution_time": 120,  # Increased execution time for detailed processing
                "early_stopping_method": "force"  # Use supported method
            }
            
            # Only add memory if it exists and is properly initialized
            if memory is not None:
                try:
                    # Test if memory is working properly
                    if hasattr(memory, 'load_memory_variables'):
                        test_vars = memory.load_memory_variables({})
                        executor_config["memory"] = memory
                        print(f"   ðŸ’­ Memory: Connected successfully")
                    else:
                        print(f"   ðŸ’­ Memory: Invalid memory object, proceeding without memory")
                        memory = None
                except Exception as e:
                    print(f"   ðŸ’­ Memory: Failed to initialize ({str(e)}), proceeding without memory")
                    memory = None
            else:
                print(f"   ðŸ’­ Memory: None")
                
            executor = AgentExecutor(**executor_config)

            # Enhanced logging
            print(f"\nðŸ¤– REACT AGENT EXECUTION")
            print(f"   ðŸ“ Input: {str(runtime_inputs)[:60]}...")
            print(f"   ðŸ› ï¸  Tools: {[tool.name for tool in tools_list]}")
            
            # Memory context debug
            if memory and hasattr(memory, 'chat_memory') and hasattr(memory.chat_memory, 'messages'):
                messages = memory.chat_memory.messages
                print(f"   ðŸ’­ Memory: {len(messages)} messages")
            else:
                print(f"   ðŸ’­ Memory: None")
            
            # Handle runtime_inputs being either dict or string
            if isinstance(runtime_inputs, str):
                user_input = runtime_inputs
            elif isinstance(runtime_inputs, dict):
                user_input = runtime_inputs.get("input", inputs.get("input", ""))
            else:
                user_input = inputs.get("input", "")
            
            # ðŸ”¥ CRITICAL FIX: Load conversation history from memory
            conversation_history = ""
            if memory is not None:
                try:
                    # Load memory variables to get conversation history
                    memory_vars = memory.load_memory_variables({})
                    if memory_vars:
                        # Get the memory key (usually "memory" or "history")
                        memory_key = getattr(memory, 'memory_key', 'memory')
                        if memory_key in memory_vars:
                            history_content = memory_vars[memory_key]
                            if isinstance(history_content, list):
                                # Format message list into readable conversation
                                formatted_history = []
                                for msg in history_content:
                                    if hasattr(msg, 'type') and hasattr(msg, 'content'):
                                        role = "Human" if msg.type == "human" else "Assistant"
                                        formatted_history.append(f"{role}: {msg.content}")
                                    elif isinstance(msg, dict):
                                        role = "Human" if msg.get('type') == 'human' else "Assistant"
                                        formatted_history.append(f"{role}: {msg.get('content', '')}")
                                
                                if formatted_history:
                                    conversation_history = "\n".join(formatted_history[-10:])  # Last 10 messages
                                    print(f"   ðŸ’­ Loaded conversation history: {len(formatted_history)} messages")
                            elif isinstance(history_content, str) and history_content.strip():
                                conversation_history = history_content
                                print(f"   ðŸ’­ Loaded conversation history: {len(history_content)} chars")
                except Exception as memory_error:
                    print(f"   âš ï¸  Failed to load memory variables: {memory_error}")
                    conversation_history = ""
            
            final_input = {
                "input": user_input,
                "tools": tools_list,  # Required for LangChain create_react_agent
                "tool_names": [tool.name for tool in tools_list],
                "chat_history": conversation_history  # Add conversation history to input
            }
            
            print(f"   âš™ï¸  Executing with input: '{final_input['input'][:50]}...'")
            
            # Execute the agent with comprehensive Unicode error handling
            try:
                result = executor.invoke(final_input)

                # Debug: Check memory after execution (AgentExecutor handles saving automatically)
                if memory is not None and hasattr(memory, 'chat_memory') and hasattr(memory.chat_memory, 'messages'):
                    new_message_count = len(memory.chat_memory.messages)
                    print(f"   ðŸ“š Memory now contains: {new_message_count} messages")

                return result

            except UnicodeEncodeError as unicode_error:
                print(f"[ERROR] Unicode encoding error: {unicode_error}")
                # Fallback: Try to encode the result with UTF-8
                try:
                    error_result = {
                        "error": f"Unicode encoding error: {str(unicode_error)}",
                        "suggestion": "Ensure UTF-8 encoding is enabled and retry the request."
                    }
                    return error_result
                except:
                    return {"error": "Unicode encoding error occurred"}

            except Exception as e:
                error_msg = f"Agent execution failed: {str(e)}"
                print(f"[ERROR] {error_msg}")
                return {"error": error_msg}

        return RunnableLambda(agent_executor_lambda)

    def _prepare_tools(self, tools_input: Any) -> list[BaseTool]:
        """Ensures the tools are in the correct list format, including retriever tools."""
        if not tools_input:
            return []
        
        tools_list = []
        
        # Handle different input types
        if isinstance(tools_input, list):
            for tool in tools_input:
                if isinstance(tool, BaseTool):
                    tools_list.append(tool)
                elif isinstance(tool, BaseRetriever):
                    # Convert retriever to tool
                    retriever_tool = create_retriever_tool(
                        name="document_retriever",
                        description="Search and retrieve relevant documents from the knowledge base",
                        retriever=tool,
                    )
                    tools_list.append(retriever_tool)
        elif isinstance(tools_input, BaseTool):
            tools_list.append(tools_input)
        elif isinstance(tools_input, BaseRetriever):
            # Convert single retriever to tool
            retriever_tool = create_retriever_tool(
                name="document_retriever", 
                description="Search and retrieve relevant documents from the knowledge base",
                retriever=tools_input,
            )
            tools_list.append(retriever_tool)
        
        return tools_list

    def _create_prompt(self, tools: list[BaseTool]) -> PromptTemplate:
        """
        Legacy method for backward compatibility. Creates a unified ReAct-compatible prompt.
        """
        return self._create_language_specific_prompt(tools, 'en')  # Default to English

    def _create_language_specific_prompt(self, tools: list[BaseTool], language_code: str) -> PromptTemplate:
        """
        Creates a language-specific ReAct-compatible prompt with mandatory language enforcement.
        Uses custom prompt_instructions if provided, otherwise falls back to smart orchestration.
        """
        custom_instructions = self.user_data.get("system_prompt", "").strip()

        # Get language-specific system context
        language_specific_context = get_language_specific_prompt(language_code)

        # Build dynamic, intelligent prompt based on available components
        prompt_content = self._build_intelligent_prompt(custom_instructions, language_specific_context, language_code)

        return PromptTemplate.from_template(prompt_content)

    def _build_intelligent_prompt(self, custom_instructions: str, base_system_context: str, language_code: str = 'en') -> str:
        """
        Builds an intelligent, dynamic system prompt that adapts to available tools, memory, and custom instructions.
        This creates a context-aware agent that understands its capabilities and constraints with mandatory language enforcement.
        """

        # === SIMPLE IDENTITY SECTION ===
        if custom_instructions:
            identity_section = f"{custom_instructions}\n\n{base_system_context}"
        else:
            identity_section = base_system_context

        # Language-specific guidelines - FORCE TOOL USAGE with DETAILED RESPONSES
        language_guidelines = {
            'en': "Provide detailed, step-by-step, and comprehensive answers. Always use the available tools and present the findings clearly. Never give generic responses; respond in clear, professional English."
        }

        simplified_guidelines = language_guidelines.get(language_code, language_guidelines['en'])

        # === REACT TEMPLATE (ENGLISH ONLY) ===
        react_template = """You are a helpful assistant that uses available tools to answer user questions.

Conversation History:
{chat_history}

Available Tools:
{tools}

Tool Names: {tool_names}

IMPORTANT: End every response with "Final Answer:" and ensure the reply is written in English.

SPECIAL CASES:
- If asked about your identity, purpose, or role: Introduce yourself using the system context.
- For Data Touch topics: Always use document_retriever first and incorporate the findings.
- For general questions: Prefer using tools when helpful before producing an answer.

Use this format:
Question: {input}
Thought: [If the user is asking about my identity or role, I can answer directly. Otherwise, I'll use tools.]
Action: document_retriever
Action Input: [search query]
Observation: [results]
Thought: I'll provide a helpful answer.
Final Answer: [Answer using tool results or system context as appropriate, in English]

Question: {input}
Thought:{agent_scratchpad}"""

        # === COMBINE ALL SECTIONS ===
        full_prompt = f"""
{identity_section}

{simplified_guidelines}

{react_template}
"""

        return full_prompt.strip()

# Alias for frontend compatibility
ToolAgentNode = ReactAgentNode
